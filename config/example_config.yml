# Example config file containing all possible options for CTLearn, whether
# they're required or optional, their datatypes, and default arguments.
#
# For an explanation of the data format and valid column names for the
# selection_string, array_info, and event_info Data config options, see
# https://github.com/cta-observatory/dl1-data-handler/wiki/CTA-ML-Data-Format
# or use ViTables http://vitables.org/ to examine the HDF5 files directly.
---

Logging:
    # Path to directory to store TensorFlow model checkpoints and summaries.
    # A timestamped copy of the configuration file will also be put here.
    # Required string.
    model_directory: '/tmp/logs/example/'

    # Optional string.
    # Path to directory to the ctlearn additional scripts.
    # Selecting this string will automatically rename the 
    # run folders int the 'model_directory' above.
    scripts_directory: 'my/path/to/ctlearn/scripts/'

Data:
    # Either a list of data file paths,
    # or a path to a file listing data file paths, one per line.
    # Required list or string.
    file_list: '/tmp/dataset/file_list.txt'

    # Type of examples to load.
    # Optional string. Default: 'mono'
    # Valid options:
    #   - 'mono': single images of one telescope type
    #   - 'stereo': events of one telescope type
    #   - 'multi-stereo': events including multiple telescope types
    mode: 'mono'

    # Telescope type or list thereof to load.
    # Optional string (mono or stereo) or list of strings (multi-stereo).
    # Default in mono or stereo mode: first telescope type in the dataset
    # Default in multi-stereo mode: all telescope types in the dataset
    # Valid telescope types:
    #   - 'LST_LSTCam': LST Telescope and Camera
    #   - 'MST_FlashCam': MST Telescope with FlashCAM Camera
    #   - 'MST_NectarCam': MST Telescope with NectarCAM Camera
    #   - 'SCT_SCTCam': SCT Telescope and Camera
    #   - 'SST1M_DigiCam': SST-1M Telescope with DigiCam Camera
    #   - 'SSTASTRI_ASTRICam': SST-2M ASTRI Telescope and Camera
    #   - 'SSTGCT_CHEC': SST-2M GCT Telescope with CHEC Camera
    # Camera images from the following telescopes can be read, but writers
    # for the data are not yet available:
    #   - FACT, HESS-I, HESS-II, MAGIC, VERITAS
    selected_telescope_type: 'LST_LSTCam'

    # Subset of telescope IDs to include of the selected telescope types.
    # Optional dictionary with string keys and list of integer values.
    # Valid keys are the telescope types listed above, and valid values are
    # are the tel_ids of the telescopes to load of that telescope type.
    # Default if not provided or telescope type not in dict: load all
    # telescopes of that telescope type if selected.
    selected_telescope_ids:
        'LST_LSTCam': [1, 2, 3, 4]

    # PyTables cut condition to apply selection cuts to events.
    # Optional string. Default: don't apply any cuts
    # See https://www.pytables.org/usersguide/condition_syntax.html
    # for explanation of syntax.
    selection_string: '(mc_energy > 1.0) & (h_first_int < 20000)'

    # Event selection filters to apply to each data file.
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing filter.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing filter.
    #               Default: 'utils'
    #   - 'name': Required string. Name of filter.
    #   - 'args': Optional dictionary. Arguments to pass to filter using
    #             filter(file, **args). Default: {}
    # Valid filter names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    event_selection:
        -
            name: 'event_intensity_filter'
            args: {i_min: 100, i_max: 316}
#       -
#           path: '/path/to/my/module/'
#           module: 'my_filter'
#           name: 'filter_fn'
#           args: {'arg1': 'foo', 'arg2': 3.14}

    # Image selection filters to apply to each image (mono mode only).
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing filter.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing filter.
    #               Default: 'utils'
    #   - 'name': Required string. Name of filter.
    #   - 'args': Optional dictionary. Arguments to pass to filter using
    #             filter(file, **args). Default: {}
    # Valid filter names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    image_selection:
        -
            name: 'image_intensity_filter'
            args: {i_min: 10, i_max: 31.6}
#       -
#           path: '/path/to/my/module/'
#           module: 'my_filter'
#           name: 'filter_fn'
#           args: {'arg1': 'foo', 'arg2': 3.14}

    # Whether to shuffle the examples.
    # Optional Boolean. Default: False
    shuffle: false

    # Seed for shuffling the examples. Only used if shuffle is true.
    # Optional integer. Default: use default random initialization.
    seed: 1234

    # Image channels to load.
    # Optional list of strings. Default: ['charge']
    # Valid options are 'charge' and 'peakpos', or whichever columns are in
    # the telescope tables of your data files.
    image_channels: ['charge']

    # Settings passed directly as arguments to ImageMapper.
    # Optional dictionary. Default: {}
    #
    # The camera types supported by ImageMapper that can be used in
    # the settings below are 'ASTRICam', 'CHEC', 'DigiCam', 'FACT',
    # 'FlashCam', 'HESS-I', 'HESS-II', 'LSTCam', 'MAGICCam', 'NectarCam',
    # 'SCTCam', and 'VERITAS'.
    mapping_settings:

        # List of camera types to calculate mapping tables for.
        # Optional list of camera type strings.
        # Default: calculate mapping tables for all supported camera types
        camera_types: ['LSTCam']

        # Algorithm to convert image vectors to rectangular arrays
        # Optional dictionary with string keys and string values.
        # Default: 'oversampling' for all camera types not in the dictionary
        # Valid keys are any camera types supported by ImageMapper.
        # Valid mapping method options (values):
        #   - 'oversampling': Convert each hexagonal pixel to four square
        #       pixels and reweight the charge to realign to a square grid
        #   - 'rebinning': Interpret the intensity as a histogram and rebin
        #       the hexagonal histogram into a square one.
        #   - 'nearest_interpolation': Perform nearest neighbor
        #   - 'bilinear_interpolation': Draw Delaunay triangulation and
        #       perform bilinear interpolation
        #   - 'bicubic_interpolation': Draw Delaunay triangulation and
        #       perform bicubic interpolation
        #   - 'image_shifting': Shift pixels of alternate rows (hexagonal
        #       cameras only)
        #   - 'axial_addressing': Warp images by relabeling axes (hexagonal
        #       cameras only)
        mapping_method:
            'LSTCam': 'bilinear_interpolation'

        # Number of padding pixels to add around each edge of the mapped image.
        # A value of 1 will increase both the image height and width by 2, etc.
        # Optional dictionary with camera type string keys and integer values.
        # Default: 0 for any camera type not specified
        padding:
            'LSTCam': 2
            'FlashCam': 1
            'NectarCam': 2
            'SCTCam': 4
            'DigiCam': 1
            'ASTRICam': 0
            'CHEC': 0
            'VERITAS': 1

        # Shape of mapped image to return. Used only for mapping methods
        # without a fixed output shape: rebinning, nearest interpolation,
        # bilinear interpolation, bicubic interpolation
        # Optional dictionary with camera type string keys and values that
        # are lists of three integers: (<width>, <length>, <num_channels>)
        interpolation_image_shape:
            'LSTCam': [110, 110, 1]

        # Explicitly set output grid points outside the camera to 0
        # when performing bilinear and bicubic interpolation.
        # Optional Boolean. Default: false
        mask_interpolation: false

    # Auxiliary information to return from the Array Information table.
    # Optional list of strings. Default: return no array info
    # Valid options are columns in the Array_Information table.
    array_info: ['x', 'y', 'z']

    # Auxiliary information to return from the Events table.
    # Optional list of strings. Default: return no event info
    # Valid options are columns in the Events table.
    # These options have to be in consonance with the 'label_names' in 'Model'.
    event_info: ['shower_primary_id', 'mc_energy', 'alt', 'az', 'core_x', 'core_y', 'x_max']

    # Transforms to apply to the data, in order.
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing Transform.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing Transform.
    #               Default: 'processor'
    #   - 'name': Required string. Name of Transform.
    #   - 'args': Optional dictionary. Arguments to pass to transform using
    #             Transform(**args). Default: {}
    # Valid transform names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    transforms:
        -
            name: 'ShowerPrimaryID'
        -
            name: 'NormalizeTelescopePositions'
            args: {'norm_x': 1.0, 'norm_y': 1.0, 'norm_z': 1.0}
#       -
#           path: '/path/to/my/module/'
#           module: 'my_transform'
#           name: 'MyTransform'
#           args: {'arg1': 'foo', 'arg2': 3.14}

    # Whether to validate that the shape and dtype of the processed data
    # matches the example description.
    # Recommended setting is True while developing the network and False
    # during production.
    # Optional Boolean. Default: False
    validate_processor: False

# Settings for the TensorFlow Estimator input_fn.
Input:

    # Random seed for shuffling the dataset.
    # Optional integer. Default: use default TensorFlow behavior
    seed: null

    # Number of consecutive examples to combine into a batch.
    # Optional integer. Default: 1
    batch_size: 32

    # Arguments to tf.data.experimental.prefetch_to_device
    # to prefetch examples to a specified device.
    # Optional dictionary or null. Default if null: do not prefetch
    prefetch_to_device:
        # Device to which to prefetch (string)
        device: "/gpu:0"
        # Number of elements to prefetch
        # Optional; will be automatically optimized if missing or null
        buffer_size: null

# Settings for the TensorFlow model. The options in this and the
# Model Parameters section are passed to the Estimator model_fn
# and the user's model function.
Model:

    # Optional string or null. Default if missing or null is to load
    # CTLearn default models directory: 'ctlearn/ctlearn/default_models/'
    # Path to directory containing model module.
    model_directory: null  # '/my/model/path/'

    # Required dictionary containing a module/function pair.
    # Module in model directory and function in module implementing the model.
    # Module and function pairs included with CTLearn:
    #   - {module: 'single_cnn', function: 'single_cnn_model'}: single
    #       telescope model using a basic convolutional neural network (CNN)
    #   - {module: 'res_net', function: 'res_net_model'}: Residual block
    #       model using a basic convolutional neural network (CNN)
    #   - {module: 'cnn_rnn', function: 'cnn_rnn_model'}: array model
    #       feeding output of a basic CNN for each  telescope into a
    #       recurrent neural network (RNN)
    #   - {module: 'variable_input_model', function: 'variable_input_model'}:
    #       array model feeding combined outputs of a CNN for each
    #       telescope into a CNN network head
    model: {module: 'single_cnn', function: 'single_cnn_model'}

    # Dictionary of tasks where the values contain the fully connected layers
    # head of each task. The final loss is calculated with a weighted sum 
    # over the individual losses. Currently the weights are constanst values.
    # For the classification task, the class names are passed into the dict
    # in order of class label (0 to n-1).
    # Optional dictionary with string keys and values either null or
    # a list of strings. Default: {}
    #
    # These options have to be in consonance with the 'event_info' and 
    # 'transforms' in 'Data'.
    # Requirements/recommendations (see also config files from benchmarks):
    #   - 'particletype':
    #       event_info:
    #           - 'shower_primary_id'
    #       transforms:
    #           -  name: 'ShowerPrimaryID'
    #              args: {name: 'particletype'}
    #
    #   - 'energy':
    #       event_info:
    #           - 'mc_energy'
    #       transforms:
    #           -  name: 'MCEnergy'
    #
    #   - 'direction':
    #       event_info:
    #           - 'mc_energy'
    #           - 'alt'
    #           - 'az'
    #       transforms:
    #           -  name: 'MCEnergy'
    #           - name: 'DeltaAltAz'
    #
    tasks:
        particletype: {class_names: ['proton', 'gamma'], fc_head: [512, 256, 2], weight: 1.0}
        #energy: {fc_head: [256, 1], weight: 1.0}
        #direction: {fc_head: [256, 2], weight: 1.0}
        #impact: {fc_head: [256, 2], weight: 1.0}
        #showermaximum: {fc_head: [256, 1], weight: 1.0}

# The options in this and the Model section are passed in a dictionary
# called "params" to the model function.
# The config option 'model_directory' above is included in params as well.
# None of these options are accessed anywhere outside the model, so
# arbitrary options may be added here. This permits custom configuration
# of user-provided models.
# Below are listed the configuration options for the CTLearn included
# models, which are only accessed if using those models.
Model Parameters:
    single_cnn:
        # Required dict with keys 'module' and 'function' & string values.
        # Module and function for image classification network.
        # Valid options:
        #   - {module: 'basic', function: 'conv_block'}
        network: {module: 'basic', function: 'conv_block'}
        # Required string or null.
        # Path to a checkpoint file or model directory from which to load
        # pretrained network weights. If null, don't load any weights.
        pretrained_weights: null

    res_net:
        # Required dict with keys 'module' and 'function' & string values.
        # Module and function for ResNet models.
        # Valid options:
        #   - {module: 'resnet_engine', function: 'stacked_res_blocks'}
        network: {module: 'resnet_engine', function: 'stacked_res_blocks'}
        # Optional arguments for the first Conv2D and MaxPool layer
        # of the ResNet model.
        init_layer: {filters: 64, kernel_size: 7, strides: 1}
        init_max_pool: {size: 3, strides: 2}
        # Required string or null.
        # Path to a checkpoint file or model directory from which to load
        # pretrained network weights. If null, don't load any weights.
        pretrained_weights: null

    cnn_rnn:
        # Required dict with keys 'module' and 'function' & string values.
        # Module and function for single telescope CNN.
        # Valid options:
        #   - {module: 'basic', function: 'conv_block'}
        cnn_block: {module: 'basic', function: 'conv_block'}

        # Required string or null.
        # Path to a checkpoint file or model directory from which to load
        # pretrained CNN block weights. If null, don't load any weights.
        pretrained_weights: null

        # Optional float. Default: 0.5
        # Dropout rate of dropout layers.
        dropout_rate: 0.5

    variable_input_model:
        # Required dict with keys 'module' and 'function' & string values.
        # Module and function for single telescope CNN.
        # Valid options:
        #   - {module: 'basic', function: 'conv_block'}
        cnn_block: {module: 'basic', function: 'conv_block'}

        # Required string.
        # Valid options:
        #   - 'vector': Use for network heads expecting an input vector
        #   - 'feature_maps': Use for networks heads expecting input as
        #       a stack of feature maps as used for convolutional layers
        telescope_combination: 'feature_maps'

        # Required dict with keys 'module' and 'function' & string values.
        # Module and function for network head.
        # Valid options:
        #   - {module: 'basic', function: 'fc_head'}
        #   - {module: 'basic', function: 'conv_head'}
        network_head: {module: 'basic', function: 'conv_head'}

        # Required string or null.
        # Path to a checkpoint file or model directory from which to load
        # pretrained CNN block weights. If null, don't load any weights.
        pretrained_weights: null

    basic:
        conv_block:
            # Required list of dicts with keys 'filters', 'kernel_size' and number
            # with integer values.
            # If number value is not stored will be automatically set to 1
            # Filter dimension and kernel size for the CNN block
            # convolutional layers.
            # Number for the desired number of convolutional layers 
            layers:
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 64, kernel_size: 3, number: 1}
                - {filters: 128, kernel_size: 3, number: 1}

            # Required dictionary with keys 'size' and 'strides' and
            # integer values, or null.
            # Max pool size and strides. If null, don't perform any pooling.
            max_pool: {size: 2, strides: 2}

            # Required integer or null.
            # Number of output filters of a final 1x1 convolutional layer.
            # If null, don't include this bottleneck layer.
            bottleneck: null

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # convolutional layer. Exercise caution when using with
            # array-level models.
            batchnorm: false

        fc_head:
            # Required list of integers.
            # Number of units for each fully-connected head dense layer.
            layers: [1024, 512, 256, 128, 64]

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # dense layer.
            batchnorm: false

        conv_head:
            # Required list of dicts with keys 'filters' and 'kernel_size'
            # with integer values.
            # Filter dimension and kernel size for the convolutional
            # network head layers.
            layers:
                - {filters: 64, kernel_size: 3}
                - {filters: 128, kernel_size: 3}
                - {filters: 256, kernel_size: 3}

            # Optional Boolean. Default: true
            # Whether to perform average pooling over spatial dimensions
            # of the convolutional output before calculating final output.
            final_avg_pool: true

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # convolutional layer.
            batchnorm: false

        # Optional float. Default: 0.99
        # Decay parameter for batch normalization layers.
        batchnorm_decay: 0.99

    resnet_engine:
        stacked_res_blocks:
            # Optional string. Default: 'bottleneck'
            # Type of the residual block.
            # Valid options:
            #   - 'basic'
            #   - 'bottleneck'
            residual_block: 'bottleneck'

            # Required list of dicts with keys 'filters' and 'blocks'
            # with integer values.
            # Filter dimension and number of blocks for the ResNet 
            # architecture.
            # Typical ResNet architectures:
            # Thin-ResNet
            #- {filters: 48, blocks: 2}
            #- {filters: 96, blocks: 3}
            #- {filters: 128, blocks: 3}
            #- {filters: 256, blocks: 3}
            # ResNet50
            #- {filters: 64, blocks: 3}
            #- {filters: 128, blocks: 4}
            #- {filters: 256, blocks: 6}
            #- {filters: 512, blocks: 3}
            architecture:
                - {filters: 48, blocks: 2}
                - {filters: 96, blocks: 3}
                - {filters: 128, blocks: 3}
                - {filters: 256, blocks: 3}

    # Optional dict of attention mechanisms.
    # Valid options:
    #   Dual attention (Spatial and channel squeeze-and-excitation attention)
    #   - {mechanism: 'Squeeze-and-Excitation', ratio: 16}
    #   Channel Squeeze-and-excitation attention
    #   - {mechanism: 'Channel-Squeeze-and-Excitation', ratio: 4}
    #   Spatial squeeze-and-excitatiom attention
    #   - {mechanism: 'Spatial-Squeeze-and-Excitation'}
    # References:
    # - [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)
    # - [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)
    attention: {mechanism: 'Squeeze-and-Excitation', ratio: 16}

Training:

    # Optional float. Default: 0.1
    # Randomly chosen fraction of data to set aside for validation.
    validation_split: 0.1

    # Required number of epochs on which to train.
    num_epochs: 20

    # Required string.
    # Valid options: ['Adadelta', 'Adam', 'RMSProp', 'SGD']
    # Optimizer function for training.
    optimizer: 'Adam'

    # Optional float. Required if optimizer is 'Adam', ignored otherwise.
    # Epsilon parameter for the Adam optimizer.
    adam_epsilon: 1.0e-8

    # Required integer.
    # Base learning rate before scaling or annealing.
    base_learning_rate: 0.001

    # Required Boolean.
    # Whether to scale the learning rate inversely proportional to the
    # number of triggered telescopes. Not used for single tel models.
    scale_learning_rate: false

    # Required Boolean.
    # Whether to weight the loss to rebalance unequal classes.
    apply_class_weights: false

    # Required string or null. If provided, train on only variables
    # within the scope matching this name, freezing all others. This is
    # useful when loading pretrained weights. If null, train on all
    # trainable variables.
    variables_to_train: null

Evaluation:

    # Required Boolean.
    # Whether to run TensorFlow standard evaluation.
    tensorflow: true

    # Optional settings for the EvalSpec.
    # Int. Positive number of steps for which to evaluate model.
    # If None, evaluates until input_fn raises an end-of-input exception.
    eval_steps: null
    # Int. Start evaluating after waiting for this many seconds.
    start_delay_secs: 120
    # Int. Do not re-evaluate unless the last evaluation was started at least
    # this many seconds ago. Of course, evaluation does not occur if no new
    # checkpoints are available, hence, this is the minimum. 
    throttle_secs: 600
    
Prediction:

    # Required string if running in predict mode.
    # Name of the file to save predictions.
    file: 'ctlearn_prediction'

    # A dict of either a list of data file paths,
    # or a path to a file listing data file paths, one per line.
    # Required dict of list or string if running in predict mode.
    prediction_file_lists: 
        'prediction_file_list1': '/tmp/dataset/prediction_file_list1.txt'
        'prediction_file_list2': '/tmp/dataset/prediction_file_list2.txt'

    # Save the true labels along with the predictions.
    # Optional Boolearn. Default: false
    save_labels: false

    # Save the example identifiers along with the predictions.
    # Mono mode: obs_id, event_id, tel_id
    # Stereo or multi-stereo mode: obs_id, event_id
    # Optional Boolearn. Default: false
    save_identifiers: false

TensorFlow:
    # Optional Boolean. Default: false
    # Whether to run TensorFlow debugger.
    run_TFDBG: false

# Optional: used in run_multiple_configurations.py only
Multiple Configurations Settings:
    # Required string.
    # Path to file to save configuration combination for each run for reference.
    run_combinations_path: '/tmp/run_combinations.yml'

    # Optional integer. Default: 1
    # Number of grouped range values to generate. All range values with null
    # num_values are grouped so that random values are generated for each
    # combination of parameters, not for each parameter separately. Ignored for
    # ungrouped range values, that is, where num_values is specified.
    num_grouped_range_values: 5

# Optional: used in run_multiple_configurations.py only
# Each item in this section has the form
# <config_nickname>:
#   config: list of the keys to access the config parameter in config file
#   value_type: one of
#       - 'list': values is a list of possible values
#       - 'range': values is a dictionary as described below
#       - 'grouped': values is a dictionary of <group_name>: value
#   values: list or dictionary as specified by the value_type
#
# The values section for a config option with value_type 'range' has the form:
# values:
#   lower_bound: Required integer. Lower bound of the range.
#   upper_bound: Required integer. Upper bound of the range.
#   spacing: Required string. Valid options:
#       - 'log': generate values uniformly using logarithmic spacing
#       - 'linear': generate values uniformly using linear spacing
#   selection: Required string. Valid options:
#       - 'random': Select values at random from a uniform distribution
#       - 'grid': Select values from an evenly-spaced grid
#   num_values: Required integer or null. Number of values to generate. All
#       range configs with num_values null are grouped together with
#       num_grouped_range_values the total number of values generated. The
#       recommended usage in most cases is to specify num_values for grid
#       selection and set to null for random selection.
Multiple Configurations Values:
    learning_rate:
        config: ['Training', 'base_learning_rate']
        value_type: 'range'
        values:
            lower_bound: 1.0e-6
            upper_bound: 1.0e-3
            spacing: 'log'
            selection: 'random'
            num_values: null
    multiplicity_cut:
        config: ['Data', 'selection_string']
        value_type: 'list'
        values:
            - 'mc_energy < 1.0'
            - 'mc_energy >= 1.0'
    telescope_type:
        config: ['Data', 'selected_telescope_type']
        value_type: 'grouped'
        values:
            'LST_LSTCam': 'LST_LSTCam'
            'MST_NectarCam': 'MST_NectarCam'
    selected_telescopes:
        config: ['Data', 'selected_telescope_ids']
        value_type: 'grouped'
        values:
            'LST_LSTCam': [1, 2, 3, 4]
            'MST_NectarCam': [30, 31, 32, 33]
    network_type:
        config: ['Model', 'model']
        value_type: 'grouped'
        values:
            CNN_RNN:
                module: 'cnn_rnn'
                function: 'cnn_rnn_model'
            variable_input:
                module: 'variable_input_model'
                function: 'variable_input_model'
    # Not yet implemented!
    telescope_sorting:
        config: ['Data', 'transforms']
        value_type: 'grouped'
        values:
            CNN_RNN: [{name: SortImages, args: {'order': 'size'}}]
            variable_input: null
